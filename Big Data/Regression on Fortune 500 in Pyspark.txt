pip install pyspark
from pyspark import SparkConf, SparkContext
from pyspark.sql import SQLContext
sc = SparkContext()
sqlContext = SQLContext(sc)
company_df = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('/content/sample_data/Fortune5002017.csv')
company_df.take(1)
company_df.cache()
company_df.printSchema()
company_df.describe().toPandas().transpose()

import pandas as pd
numeric_features = [t[0] for t in company_df.dtypes if t[1] == 'int' or t[1] == 'double']
sampled_data = company_df.select(numeric_features).sample(False, 0.8).toPandas()

from pandas.plotting import scatter_matrix

axs = scatter_matrix(sampled_data, figsize=(10, 10))
n = len(sampled_data.columns)
for i in range(n):
	v = axs[i, 0]
	v.yaxis.label.set_rotation(0)
	v.yaxis.label.set_ha('right')
	v.set_yticks(())
	h = axs[n-1, i]
	h.xaxis.label.set_rotation(90)
	h.set_xticks(())

import six
for i in company_df.columns:
	if not( isinstance(company_df.select(i).take(1)[0][0], six.string_types)):
		print( "Correlation to Employees for ", i, company_df.stat.corr('Number of Employees',i))

from pyspark.ml.feature import VectorAssembler
vectorAssembler = VectorAssembler(inputCols = ['Rank', 'Number of Employees'], outputCol = 'features')

tcompany_df = vectorAssembler.transform(company_df)
tcompany_df = tcompany_df.select(['features', 'Number of Employees'])
tcompany_df.show(3)

splits = tcompany_df.randomSplit([0.7, 0.3])
train_df = splits[0]
test_df = splits[1]

from pyspark.ml.regression import LinearRegression
lr = LinearRegression(featuresCol = 'features', labelCol='Number of Employees', maxIter=10, regParam=0.3, elasticNetParam=0.8)
lr_model = lr.fit(train_df)
print("Coefficients: " + str(lr_model.coefficients))
print("Intercept: " + str(lr_model.intercept))
